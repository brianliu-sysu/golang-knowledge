# **Benchmark**
Benchmark is a tool used to measure code perference, telling you how fast your code runs and how much memory it uses.

## Basic structure
```
// xxx_test.go
package xxx

func BenchmarkFuncName(b *testing.B) {
    // optionalï¼š Initialization
    setup()

    b.ResetTimer() // reset the timer to exclude the initialization time

    for i := range b.N {
        // code under test
        funcToTest()
    }
}

// subtest
func BenchmarkConcat(b *testing.B) {
    sizes := []{10, 100, 1000}

    for _, size := range sizes {
        b.Run(fmt.Sprint("size=%d", size), func(b *testing.B) {
            for i := range b.N {
                concat(size)
            }
        })
    }
}

// parallel testing
func BenchnarkParallel(b *testing.B) {
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            doWork()
        }
    })
}
```
Key Points:
* the filename must end with `_test.go`
* the function name must start with `Benchmark`
* the parameter must be `*testing.B`
* Loop b.N times (the frame automatically adjust the value of N)

## run Benchamark
```
# run all benchmark
go test -bench=.

# run a special benchmark
go test -bench=BenchmarkFuncName

# regular match
go test -bench="Concat"

# specify run time
go test -bench=. -benchtime=5s

# specify the number of runs
go test -bench=. -benchtime=1000x

# take the average after multiple runs
go test -bench=. -count=5
```
## benchmem: memory analysis
```
go test -bench=. -benchmem
```

**Output interpretation**
**Benchmark è¾“å‡ºæ ¼å¼è§£æžï¼š**

```
BenchmarkConcat-8    5000000    300 ns/op    64 B/op    2 allocs/op
```

| å­—æ®µ | ç¤ºä¾‹å€¼ | è¯´æ˜Ž |
|------|--------|------|
| å‡½æ•°å | `BenchmarkConcat` | è¢«æµ‹è¯•çš„ Benchmark å‡½æ•° |
| CPU æ ¸å¿ƒæ•° | `-8` | GOMAXPROCS å€¼ï¼ˆå¹¶è¡Œåº¦ï¼‰ |
| è¿è¡Œæ¬¡æ•° | `5000000` | å‡½æ•°è¢«è°ƒç”¨çš„æ€»æ¬¡æ•° |
| æ¯æ¬¡è€—æ—¶ | `300 ns/op` | å•æ¬¡æ“ä½œå¹³å‡è€—æ—¶ |
| æ¯æ¬¡åˆ†é…å­—èŠ‚ | `64 B/op` | å•æ¬¡æ“ä½œåˆ†é…çš„å†…å­˜ï¼ˆéœ€ `-benchmem`ï¼‰ |
| æ¯æ¬¡åˆ†é…æ¬¡æ•° | `2 allocs/op` | å•æ¬¡æ“ä½œçš„å†…å­˜åˆ†é…æ¬¡æ•°ï¼ˆéœ€ `-benchmem`ï¼‰ |

> ðŸ’¡ **ä¼˜åŒ–ç›®æ ‡**ï¼šé™ä½Ž `ns/op`ã€`B/op`ã€`allocs/op` ä¸‰ä¸ªæŒ‡æ ‡

## generate profile
```
# generate CPU profile
go test -bench=. -cpuprofile=cpu.pprof

# generate memory profile
go test -bench=. -memprofile=mem.pprof

# analysis
go tool pprof cpu.pprof
go tool pprof mem.pprof
```

## comparesion tool benchstat
```
# install
go install golang.org/x/perf/cmd/benchstat@latest

# run the program multiple times and save the results
go test -bench=. -count=10 > old.txt

# Run it again after optimization
go test -bench=. -count=10 > new.txt

# Comparison
benchstat old.txt new.txt
```

## Best practices
### Benchmark Best Practices

| # | Practice | Command / Code | Purpose |
|---|----------|----------------|---------|
| 1ï¸âƒ£ | Always use `-benchmem` | `go test -bench=. -benchmem` | Check memory allocations |
| 2ï¸âƒ£ | Use `b.ResetTimer()` | `b.ResetTimer()` | Exclude initialization time |
| 3ï¸âƒ£ | Run multiple times | `go test -bench=. -count=5` | Calculate stable average |
| 4ï¸âƒ£ | Compare results | `benchstat old.txt new.txt` | Validate optimization |

**Complete Benchmark Workflow:**

```mermaid
flowchart LR
    A["1ï¸âƒ£ Write\nBenchmark"] --> B["2ï¸âƒ£ Run\n-benchmem -count=5"]
    B --> C["3ï¸âƒ£ Save\nResults"]
    C --> D["4ï¸âƒ£ Optimize\nCode"]
    D --> E["5ï¸âƒ£ Re-run\nBenchmark"]
    E --> F["6ï¸âƒ£ Compare\nbenchstat"]
    F -.->|"Iterate"| D

    style A fill:#e3f2fd,stroke:#1565c0
    style B fill:#fff3e0,stroke:#ef6c00
    style C fill:#e8f5e9,stroke:#2e7d32
    style D fill:#f3e5f5,stroke:#7b1fa2
    style E fill:#fff3e0,stroke:#ef6c00
    style F fill:#ffebee,stroke:#c62828
```

**Example Commands:**

```bash
# Run benchmark with memory stats, 5 iterations
go test -bench=. -benchmem -count=5 | tee old.txt

# After optimization, run again
go test -bench=. -benchmem -count=5 | tee new.txt

# Compare results
benchstat old.txt new.txt
```